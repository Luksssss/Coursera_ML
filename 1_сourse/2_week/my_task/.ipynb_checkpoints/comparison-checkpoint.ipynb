{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n",
    "\n",
    "Выполните следующие шаги:\n",
    "\n",
    "Скачайте файл с предложениями (sentences.txt).\n",
    "Каждая строка в файле соответствует одному предложению. Считайте их, приведите каждую к нижнему регистру с помощью строковой функции lower().\n",
    "Произведите токенизацию, то есть разбиение текстов на слова. Для этого можно воспользоваться регулярным выражением, которое считает разделителем любой символ, не являющийся буквой: re.split('[^a-z]', t). Не забудьте удалить пустые слова после разделения.\n",
    "Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict.\n",
    "Создайте матрицу размера n * d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254.\n",
    "Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание. Само предложение (In comparison to dogs, cats have not undergone... ) имеет индекс 0.\n",
    "Запишите полученные числа в файл, разделив пробелом. Обратите внимание, что файл должен состоять из одной строки, в конце которой не должно быть переноса. Пример файла с решением вы можете найти в конце задания (submission-1.txt).\n",
    "Совпадают ли ближайшие два предложения по тематике с первым? Совпадают ли тематики у следующих по близости предложений?\n",
    "Разумеется, использованный вами метод крайне простой. Например, он не учитывает формы слов (так, cat и cats он считает разными словами, хотя по сути они означают одно и то же), не удаляет из текстов артикли и прочие ненужные слова. Позже мы будем подробно изучать анализ текстов, где выясним, как достичь высокого качества в задаче поиска похожих предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 0.0), ('6', 0.7327387580875756), ('4', 0.7770887149698589), ('21', 0.8250364469440588), ('10', 0.8328165362273942), ('12', 0.8396432548525454), ('16', 0.8406361854220809), ('20', 0.8427572744917122), ('2', 0.8644738145642124), ('13', 0.8703592552895671), ('14', 0.8740118423302576), ('11', 0.8804771390665607), ('8', 0.8842724875284311), ('19', 0.8885443574849294), ('3', 0.8951715163278082), ('9', 0.9055088817476932), ('7', 0.9258750683338899), ('5', 0.9402385695332803), ('15', 0.9442721787424647), ('18', 0.9442721787424647), ('1', 0.9527544408738466), ('17', 0.956644501523794)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# считываем данные с файла\n",
    "with open('sentences.txt', 'r') as f:\n",
    "    data_list = f.readlines()\n",
    "\n",
    "# число предложений\n",
    "n = len(data_list)\n",
    "\n",
    "\n",
    "dict_words = {}\n",
    "ind = 0\n",
    "list_word_cleaned = []\n",
    "for sss in data_list:\n",
    "    ss = re.split('[^a-z]', sss.lower())\n",
    "    list_word = [word for word in ss if word]\n",
    "    list_word_cleaned.append(list_word)\n",
    "    for word in list_word:\n",
    "        if not word in dict_words:\n",
    "            dict_words[word] = ind\n",
    "            ind += 1\n",
    "            \n",
    "            \n",
    "        \n",
    "# считаем количество вхождений каждого слова в тексте (но кажется это не нужно)\n",
    "#         if word in dict_words:\n",
    "#             dict_words[word] += 1\n",
    "#         else:\n",
    "#             dict_words[word] = 1\n",
    "    \n",
    "# размерность матрицы\n",
    "m = len(data_list)\n",
    "n = len(dict_words)\n",
    "\n",
    "# создаём матрицу c нулями\n",
    "matrix = np.zeros((m,n), dtype = int)\n",
    "\n",
    "index = 0\n",
    "# обходим матрицу и заполням количеством встреченных слов в предложении\n",
    "for m in matrix:\n",
    "    my_list_word = list_word_cleaned[index]\n",
    "    for k, v in dict_words.items():\n",
    "        cnt = my_list_word.count(k)\n",
    "        if cnt > 0:\n",
    "            m[v] = cnt\n",
    "\n",
    "    index+=1\n",
    "\n",
    "# находим косинусное расстояние (чем меньше значение, тем лучше, т.е. в данном случае\n",
    "# тем больше тексты похожи друг на друга)\n",
    "index = 0\n",
    "dict_cos = {}\n",
    "for m in matrix:\n",
    "    dist_cos = cosine(matrix[0], m)\n",
    "    dict_cos[str(index)] = dist_cos\n",
    "    index+=1\n",
    "\n",
    "    \n",
    "print sorted(dict_cos.items(), key=lambda x: x[1])\n",
    "    \n",
    "\n",
    "\n",
    "# print list_word_cleaned[0]\n",
    "# print matrix[0]\n",
    "# print dict_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
