{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn import model_selection, datasets, metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./kaggle/orange_small_churn_train_data.csv', sep = ',', header = 0, index_col=0)\n",
    "test_data = pd.read_csv('./kaggle/orange_small_churn_test_data.csv', sep = ',', header = 0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18298, 230)\n",
      "(18298, 1)\n",
      "(10000, 230)\n"
     ]
    }
   ],
   "source": [
    "# т.к. в последней строке тренировочных данных ответа нету, то удаляем её\n",
    "train_data = data.iloc[:-1,:-1]\n",
    "train_labels = data.iloc[:-1,-1:]\n",
    "\n",
    "print train_data.shape\n",
    "print train_labels.shape\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отделяем числовые и категориальные признаки и удаляем полностью пустые признаки\n",
    "data_numb = train_data.iloc[:,0:190].dropna(axis=1, how='all')\n",
    "data_categ = train_data.iloc[:,190:].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = data_numb.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменим NONE на среднее значение колонки\n",
    "# Посчитаем средние по колонкам\n",
    "numeric_means = data_numb.mean(axis=0, skipna=True)\n",
    "\n",
    "# Заполним пропущенные численные значения средними\n",
    "data_numb = data_numb.fillna(numeric_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем обучить только вещественные признаки чтобы понять какие признакие самые важные\n",
    "select = RFE(GradientBoostingClassifier(n_estimators = 95, random_state=0, learning_rate=0.09, max_depth=2),\n",
    "            n_features_to_select=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-8517f342247b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'select.fit(data_numb, train_labels)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/decorator.pyc:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/feature_selection/rfe.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/feature_selection/rfe.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "select.fit(data_numb, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = array([False, False, False, False, False, False, False, False, False,\n",
    "       False, False,  True, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False,  True, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "        True, False, False, False, False, False, False, False,  True,\n",
    "        True, False, False, False, False, False,  True, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False,  True, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False,  True, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False,  True, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False,  True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_top10=[columns_name[ind] for ind, col in enumerate(support) if col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numb = data_numb[columns_top10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВЕЩЕСТВЕННЫЕ признаки\n",
    "# NOTE: сделаем скелинг численных признаков с D=1 (подробнее см. неделю 1)\n",
    "# NOTE2: такая запись по созданию нового DataFrame нужна из-за тоог что при fit_transform слетают индексы и потом\n",
    "# при контатенации у нас получается каша.\n",
    "scaler = StandardScaler()\n",
    "data_numb=pd.DataFrame(scaler.fit_transform(data_numb.values), index=data_numb.index, columns=columns_top10)\n",
    "\n",
    "# меняем пустые на 0 (0 это среднее так как признаки масштабированы)\n",
    "# data_numb.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# КАТЕГОРИАЛЬНЫЕ признаки\n",
    "# заменим пустые значения на NA (будет как доп.признак)\n",
    "data_categ = data_categ.fillna('NA').applymap(lambda s: str(s))\n",
    "\n",
    "# удалим те колонки где больше 20 категорий и меньше 2 (эти колонки не информативны)\n",
    "name_del = [name for name, var in data_categ.iteritems() if var.value_counts(dropna=True).shape[0] > 20 or var.value_counts(dropna=True).shape[0] < 2]\n",
    "data_categ = data_categ.drop(labels=name_del, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАРИАНТ 1 кодируем категориальные признаки\n",
    "# data_dummies = pd.get_dummies(data_categ)\n",
    "\n",
    "\n",
    "# ВАРИАНТ 2 one-hote-encoder\n",
    "encoder = DV(sparse = False)\n",
    "data_dummies = encoder.fit_transform(data_categ.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18298, 101)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при ВАРИАНТЕ 1\n",
    "# объединяем числовые признаки и закодированные категориальные\n",
    "# train_data = pd.concat([data_numb, data_dummies], axis=1)\n",
    "# train_data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# при ВАРИАНТЕ 2\n",
    "train_data = np.hstack((data_numb.values, data_dummies))\n",
    "# train_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18298, 10)\n",
      "(18298, 20)\n",
      "(18298, 111)\n",
      "(18298, 1)\n"
     ]
    }
   ],
   "source": [
    "print data_numb.shape\n",
    "print data_categ.shape\n",
    "\n",
    "print train_data.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0    0.924746\n",
      " 1.0    0.075254\n",
      "Name: labels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1 соответствует классу отток, -1 - классу не отток\n",
    "# как видим у нас оч большая расбалансировка классов, попробуем её уменьшить\n",
    "print train_labels[\"labels\"].value_counts()/train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем отбалансировать классы, сгенеририрем отдельно индексы для вещественных и категориальных классов\n",
    "# чтобы у нас получились как будто новые непохожие элементы.\n",
    "\n",
    "cnt_el = 15000\n",
    "\n",
    "# получаем только класс 1\n",
    "only_class_1_numb = data_numb[train_labels['labels']==1]\n",
    "only_class_1_categ = pd.DataFrame(data_dummies[train_labels['labels']==1])\n",
    "\n",
    "# сгенерировали индексы значения которых будем дублировать (добавим 15к новых элементов класса 1)\n",
    "ind_class_1_numb_to_add = np.random.randint(0, only_class_1_numb.shape[0]-1, size=cnt_el)\n",
    "ind_class_1_categ_to_add = np.random.randint(0, only_class_1_categ.shape[0]-1, size=cnt_el)\n",
    "\n",
    "# сопоставляем индексы и значения\n",
    "X_train_to_add_numb = only_class_1_numb.iloc[ind_class_1_numb_to_add]\n",
    "X_train_to_add_categ = only_class_1_categ.iloc[ind_class_1_categ_to_add]\n",
    "\n",
    "new_data_class_1 = np.hstack((X_train_to_add_numb.values, X_train_to_add_categ))\n",
    "new_labels_class_1 = pd.DataFrame(np.ones(cnt_el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 111)\n",
      "(15000, 1)\n",
      "(18298, 1)\n"
     ]
    }
   ],
   "source": [
    "print new_data_class_1.shape\n",
    "print new_labels_class_1.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(new_labels_class_1)\n",
    "print type(train_labels.values)\n",
    "\n",
    "# new_labels_class_1 = np.array([new_labels_class_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.vstack((train_data, new_data_class_1))\n",
    "train_labels = np.vstack((train_labels, new_labels_class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33298, 111)\n",
      "(33298, 1)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16377\n",
      "16921\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на баланс классов\n",
    "print len(train_labels[train_labels==1])\n",
    "print len(train_labels[train_labels==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перемешаем данные\n",
    "new_train_data = shuffle(np.hstack((train_data, train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = new_train_data[:,:-1]\n",
    "train_labels = new_train_data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33298, 111)\n",
      "(33298, 1)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth - максимальная глубина\n",
    "# learning_rate - насколько сильно каждое дерево будет пытаться исправить ошибки предыдущих деревьев.\n",
    "parameters_grid = {\n",
    "    'n_estimators' : range(90, 110, 5),\n",
    "    'learning_rate' : [0.09, 0.1, 0.11],\n",
    "    'max_depth': range(1, 4, 1)\n",
    "}\n",
    "\n",
    "# Будем использовать метод стратификации который делит соотношение классов в обучающей выборке на равное количество\n",
    "skf = model_selection.StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "classifier = GradientBoostingClassifier(random_state=0)\n",
    "grid_rfc = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'roc_auc', cv = skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 39s, sys: 2.01 s, total: 34min 41s\n",
      "Wall time: 34min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [90, 95, 100, 105], 'learning_rate': [0.09, 0.1, 0.11], 'max_depth': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.11, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=105,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8857861846433008\n",
      "{'n_estimators': 105, 'learning_rate': 0.11, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "print grid_rfc.best_score_\n",
    "print grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.11, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=105,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим модель с оптимальными параметрами которые удалось подобрать\n",
    "clf = GradientBoostingClassifier(n_estimators = 105, random_state=0, learning_rate=0.11, max_depth=3)\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем метрики на тренировочном наборе\n",
    "actual_labels = clf.predict(train_data)\n",
    "# actual_labels_proba = clf.predict_proba(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC = 0.7978940001696118\n",
      "accuracy = 0.7977055679019761\n",
      "precision = 0.7857269871376918\n",
      "recall = 0.8094278561397081\n",
      "f1 = 0.7974013474494707\n"
     ]
    }
   ],
   "source": [
    "print \"AUC_ROC =\", metrics.roc_auc_score(train_labels, actual_labels)\n",
    "print \"accuracy =\", clf.score(train_data, train_labels)\n",
    "print \"precision =\", metrics.precision_score(train_labels, actual_labels)\n",
    "print \"recall =\", metrics.recall_score(train_labels, actual_labels)\n",
    "print \"f1 =\", metrics.f1_score(train_labels, actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC_ROC = 0.5021491001564492\n",
    "# accuracy = 0.9250191277735271\n",
    "# precision = 0.8571428571428571\n",
    "# recall = 0.004357298474945534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.07890705e-02, 9.07238578e-04, 3.55577003e-03, 1.26684888e-01,\n",
       "       3.56854869e-02, 2.86772622e-02, 2.72459805e-02, 3.31044695e-01,\n",
       "       0.00000000e+00, 5.82658231e-02, 1.49232282e-03, 2.22988270e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       9.38748114e-04, 0.00000000e+00, 0.00000000e+00, 5.14969606e-04,\n",
       "       0.00000000e+00, 1.16677026e-04, 0.00000000e+00, 9.12194414e-04,\n",
       "       0.00000000e+00, 2.62050730e-04, 1.16055334e-03, 4.38800320e-06,\n",
       "       0.00000000e+00, 1.48002268e-04, 2.73007002e-02, 1.21889575e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.79542756e-04, 1.20199733e-02,\n",
       "       6.12160508e-03, 0.00000000e+00, 0.00000000e+00, 1.22121005e-04,\n",
       "       9.21120249e-04, 4.88461385e-03, 0.00000000e+00, 1.89963269e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.94228630e-04, 0.00000000e+00,\n",
       "       3.19356894e-04, 3.03460451e-03, 1.65690158e-03, 5.77443236e-03,\n",
       "       3.50571872e-02, 4.69129032e-02, 2.14341434e-03, 1.91557724e-03,\n",
       "       6.77949107e-04, 2.44526204e-03, 2.52266871e-02, 0.00000000e+00,\n",
       "       1.06441701e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.42784516e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.15792241e-04, 1.13060487e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.63229237e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.71998278e-04, 1.36375913e-04,\n",
       "       0.00000000e+00, 3.15279127e-04, 0.00000000e+00, 1.01161945e-04,\n",
       "       3.54251000e-04, 2.82266454e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.60413635e-04, 2.21151476e-03, 0.00000000e+00, 1.23174274e-04,\n",
       "       2.76610520e-04, 9.83979926e-04, 6.77466928e-04, 5.97511181e-04,\n",
       "       9.22859118e-02, 0.00000000e+00, 4.29374224e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.18917057e-02, 1.61257520e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.52949503e-02, 1.04978135e-04,\n",
       "       3.22003954e-04, 2.80135573e-04, 0.00000000e+00])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важность признаков\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестовый набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 230)\n"
     ]
    }
   ],
   "source": [
    "# Предобрабатываем тестовый набор\n",
    "print test_data.shape\n",
    "\n",
    "# отделяем числовые и категориальные признаки и удаляем полностью пустые признаки\n",
    "# data_numb_test = test_data.iloc[:,0:190].dropna(axis=1, how='all')\n",
    "data_numb_test = test_data[columns_top10]\n",
    "data_categ_test = test_data.iloc[:,190:]\n",
    "\n",
    "# data_dummies = pd.get_dummies(data_categ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВЕЩЕСТВЕННЫЕ признаки\n",
    "numeric_means_test = data_numb_test.mean(axis=0, skipna=True)\n",
    "# Заполним пропущенные численные значения средними\n",
    "data_numb_test = data_numb_test.fillna(numeric_means_test, axis=0)\n",
    "\n",
    "data_numb_test =pd.DataFrame(scaler.transform(data_numb_test.values), index=data_numb_test.index, columns=columns_top10)\n",
    "\n",
    "# data_numb_test.fillna(0, inplace=True)\n",
    "\n",
    "# КАТЕГОРИАЛЬНЫЕ ПРИЗНАКИ\n",
    "# берем только колонки используемые в обучении\n",
    "data_categ_test = data_categ_test[data_categ.columns]\n",
    "data_categ_test = data_categ_test.fillna('NA').applymap(lambda s: str(s))\n",
    "\n",
    "# удалим те колонки где больше 20 категорий и меньше 2 (эти колонки не информативны)\n",
    "# name_del = [name for name, var in data_categ_test.iteritems() if var.value_counts(dropna=True).shape[0] > 20 or var.value_counts(dropna=True).shape[0] < 2]\n",
    "# data_categ_test = data_categ_test.drop(labels=name_del, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000, 20)\n"
     ]
    }
   ],
   "source": [
    "print data_numb_test.shape\n",
    "print data_categ_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кодируем категориальные признаки\n",
    "# data_dummies_test = pd.get_dummies(data_categ_test)\n",
    "\n",
    "data_dummies_test = encoder.transform(data_categ_test.T.to_dict().values())\n",
    "# data_dummies_test = np.where(data_dummies_test == np.nan, data_dummies_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем числовые признаки и закодированные категориальные\n",
    "test_data = np.hstack((data_numb_test.values, data_dummies_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 111)\n"
     ]
    }
   ],
   "source": [
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = clf.predict(test_data)\n",
    "test_labels_proba = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраняем результат для Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_labels_proba[:,1], columns=['result'])  \n",
    "df.index.name = 'ID'\n",
    "# df['index'] = df.index\n",
    "# df.astype({\"ID\": int, \"result\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('output.csv', df, delimiter=',', fmt='%f', header='ID, result')\n",
    "df.to_csv('output.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
