{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn import model_selection, datasets, metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# Градиентный бустинг\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./kaggle/orange_small_churn_train_data.csv', sep = ',', header = 0, index_col=0)\n",
    "test_data = pd.read_csv('./kaggle/orange_small_churn_test_data.csv', sep = ',', header = 0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18298, 230)\n",
      "(18298, 1)\n",
      "(10000, 230)\n"
     ]
    }
   ],
   "source": [
    "# т.к. в последней строке тренировочных данных ответа нету, то удаляем её\n",
    "train_data = data.iloc[:-1,:-1]\n",
    "train_labels = data.iloc[:-1,-1:]\n",
    "\n",
    "print train_data.shape\n",
    "print train_labels.shape\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отделяем числовые и категориальные признаки и удаляем полностью пустые признаки\n",
    "data_numb = train_data.iloc[:,0:190].dropna(axis=1, how='all')\n",
    "data_categ = train_data.iloc[:,190:].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name_numb = data_numb.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменим NONE на среднее значение колонки\n",
    "# Посчитаем средние по колонкам\n",
    "numeric_means = data_numb.mean(axis=0, skipna=True)\n",
    "\n",
    "# Заполним пропущенные численные значения средними\n",
    "data_numb = data_numb.fillna(numeric_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВЕЩЕСТВЕННЫЕ признаки\n",
    "# NOTE: сделаем скелинг численных признаков с D=1 (подробнее см. неделю 1)\n",
    "# NOTE2: такая запись по созданию нового DataFrame нужна из-за тоог что при fit_transform слетают индексы и потом\n",
    "# при контатенации у нас получается каша.\n",
    "scaler = StandardScaler()\n",
    "data_numb=pd.DataFrame(scaler.fit_transform(data_numb.values), index=data_numb.index, columns=data_numb.columns)\n",
    "\n",
    "# меняем пустые на 0 (0 это среднее так как признаки масштабированы)\n",
    "# data_numb.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# КАТЕГОРИАЛЬНЫЕ признаки\n",
    "# заменим пустые значения на NA (будет как доп.признак)\n",
    "data_categ = data_categ.fillna('NA').applymap(lambda s: str(s))\n",
    "\n",
    "# удалим те колонки где больше 20 категорий и меньше 2 (эти колонки не информативны)\n",
    "name_del = [name for name, var in data_categ.iteritems() if var.value_counts(dropna=True).shape[0] > 20 or var.value_counts(dropna=True).shape[0] < 2]\n",
    "data_categ = data_categ.drop(labels=name_del, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАРИАНТ 1 кодируем категориальные признаки\n",
    "# data_dummies = pd.get_dummies(data_categ)\n",
    "\n",
    "\n",
    "# ВАРИАНТ 2 one-hote-encoder\n",
    "encoder = DV(sparse = False)\n",
    "data_dummies = encoder.fit_transform(data_categ.T.to_dict().values())\n",
    "\n",
    "# тут хранятся имена новых колонок\n",
    "col_names_categ=encoder.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18298, 101)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при ВАРИАНТЕ 1\n",
    "# объединяем числовые признаки и закодированные категориальные\n",
    "# train_data = pd.concat([data_numb, data_dummies], axis=1)\n",
    "# train_data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# при ВАРИАНТЕ 2\n",
    "# train_data = np.hstack((data_numb.values, data_dummies))\n",
    "\n",
    "# train_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18298, 174)\n",
      "(18298, 20)\n",
      "(18298, 230)\n",
      "(18298, 1)\n"
     ]
    }
   ],
   "source": [
    "print data_numb.shape\n",
    "print data_categ.shape\n",
    "\n",
    "print train_data.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0    0.924746\n",
      " 1.0    0.075254\n",
      "Name: labels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1 соответствует классу отток, -1 - классу не отток\n",
    "# как видим у нас оч большая расбалансировка классов, попробуем её уменьшить\n",
    "print train_labels[\"labels\"].value_counts()/train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем отбалансировать классы, сгенеририрем отдельно индексы для вещественных и категориальных классов\n",
    "# чтобы у нас получились как будто новые непохожие элементы.\n",
    "\n",
    "cnt_el = 15000\n",
    "\n",
    "# получаем только класс 1\n",
    "only_class_1_numb = data_numb[train_labels['labels']==1]\n",
    "only_class_1_categ = pd.DataFrame(data_dummies[train_labels['labels']==1])\n",
    "\n",
    "# сгенерировали индексы значения которых будем дублировать (добавим 15к новых элементов класса 1)\n",
    "ind_class_1_numb_to_add = np.random.randint(0, only_class_1_numb.shape[0]-1, size=cnt_el)\n",
    "ind_class_1_categ_to_add = np.random.randint(0, only_class_1_categ.shape[0]-1, size=cnt_el)\n",
    "\n",
    "# сопоставляем индексы и значения\n",
    "X_train_to_add_numb = only_class_1_numb.iloc[ind_class_1_numb_to_add]\n",
    "X_train_to_add_categ = only_class_1_categ.iloc[ind_class_1_categ_to_add]\n",
    "\n",
    "new_data_class_1 = np.hstack((X_train_to_add_numb.values, X_train_to_add_categ))\n",
    "new_labels_class_1 = pd.DataFrame(np.ones(cnt_el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 275)\n",
      "(15000, 1)\n",
      "(18298, 1)\n"
     ]
    }
   ],
   "source": [
    "print new_data_class_1.shape\n",
    "print new_labels_class_1.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# названия новых колонок\n",
    "columns_name = data_numb.columns.to_list() + encoder.feature_names_\n",
    "\n",
    "# вещественные+категориальные признаки\n",
    "train_data = np.hstack((data_numb.values, data_dummies))\n",
    "\n",
    "# + новые строки класса 1\n",
    "train_data = np.vstack((train_data, new_data_class_1))\n",
    "\n",
    "# + новые ответы для класса 1\n",
    "train_labels = np.vstack((train_labels, new_labels_class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33298, 275)\n",
      "(33298, 1)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16377\n",
      "16921\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на баланс классов\n",
    "print len(train_labels[train_labels==1])\n",
    "print len(train_labels[train_labels==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перемешаем данные\n",
    "new_train_data = shuffle(np.hstack((train_data, train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = new_train_data[:,:-1]\n",
    "train_labels = new_train_data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33298, 275)\n",
      "(33298, 1)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск важных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем обучить признаки чтобы понять какие признакие самые важные\n",
    "select = RFE(GradientBoostingClassifier(n_estimators = 125, random_state=0, learning_rate=0.12, max_depth=6),\n",
    "            n_features_to_select=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "select.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_xgb = RFE(xgb.XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=75, min_child_weight=2, seed=0),\n",
    "            n_features_to_select=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 33s, sys: 14.6 s, total: 50min 47s\n",
      "Wall time: 50min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=2, missing=None, n_estimators=75,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1),\n",
       "  n_features_to_select=100, step=1, verbose=0)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "select_xgb.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_xgb.n_features_to_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False,  True, False,  True, False, False, False,  True,\n",
       "       False, False,  True,  True, False,  True,  True, False,  True,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True,  True, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "        True, False, False, False,  True, False, False,  True,  True,\n",
       "        True, False,  True, False,  True, False,  True, False,  True,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "        True,  True,  True, False, False, False,  True, False,  True,\n",
       "       False, False, False,  True,  True,  True,  True, False, False,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "        True, False,  True, False,  True,  True, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "        True,  True, False,  True, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "        True,  True, False, False,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True, False, False, False, False,  True,  True, False,  True,\n",
       "        True,  True, False, False, False])"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_xgb.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_top100 = [columns_name[ind] for ind, col in enumerate(select_xgb.support_) if col]\n",
    "ind_top100= [ind for ind, col in enumerate(select_xgb.support_) if col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:, ind_top100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33298, 100)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг деревьев\n",
    "\n",
    "https://dyakonov.org/2017/06/09/%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9-%D0%B1%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth - максимальная глубина\n",
    "# learning_rate - насколько сильно каждое дерево будет пытаться исправить ошибки предыдущих деревьев.\n",
    "parameters_grid = {\n",
    "    'n_estimators' : range(85, 130, 5),\n",
    "    'learning_rate' : [0.08, 0.085, 0.09, 0.095 , 0.1, 0.105, 0.11, 0.115, 0.12],\n",
    "    'max_depth': range(1, 7, 1)\n",
    "}\n",
    "\n",
    "# Будем использовать метод стратификации который делит соотношение классов в обучающей выборке на равное количество\n",
    "skf = model_selection.StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "classifier = GradientBoostingClassifier(random_state=0)\n",
    "grid_gbc = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'roc_auc', cv = skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 12min 59s, sys: 2.36 s, total: 5h 13min 1s\n",
      "Wall time: 5h 13min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [85, 90, 95, 100, 105, 110, 115, 120, 125], 'learning_rate': [0.08, 0.085, 0.09, 0.095, 0.1, 0.105, 0.11, 0.115, 0.12], 'max_depth': [1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.12, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=125,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9573896065946136\n",
      "{'n_estimators': 125, 'learning_rate': 0.12, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "print grid_rfc.best_score_\n",
    "print grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.811287</td>\n",
       "      <td>0.110419</td>\n",
       "      <td>0.892488</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 120, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889195</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.901799</td>\n",
       "      <td>0.891492</td>\n",
       "      <td>0.901468</td>\n",
       "      <td>0.234767</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.257520</td>\n",
       "      <td>0.159539</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.902353</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 110, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889159</td>\n",
       "      <td>0.905136</td>\n",
       "      <td>0.891037</td>\n",
       "      <td>0.901514</td>\n",
       "      <td>0.891418</td>\n",
       "      <td>0.901296</td>\n",
       "      <td>0.633057</td>\n",
       "      <td>0.042878</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1.360242</td>\n",
       "      <td>0.158142</td>\n",
       "      <td>0.892244</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 90, u'c...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888494</td>\n",
       "      <td>0.904592</td>\n",
       "      <td>0.890898</td>\n",
       "      <td>0.901091</td>\n",
       "      <td>0.891957</td>\n",
       "      <td>0.901484</td>\n",
       "      <td>0.066677</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.722359</td>\n",
       "      <td>0.115429</td>\n",
       "      <td>0.892205</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 120, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890335</td>\n",
       "      <td>0.905915</td>\n",
       "      <td>0.891106</td>\n",
       "      <td>0.901407</td>\n",
       "      <td>0.891459</td>\n",
       "      <td>0.901505</td>\n",
       "      <td>0.107170</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1.300365</td>\n",
       "      <td>0.151131</td>\n",
       "      <td>0.892064</td>\n",
       "      <td>0.902070</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 100, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888496</td>\n",
       "      <td>0.904749</td>\n",
       "      <td>0.890673</td>\n",
       "      <td>0.901019</td>\n",
       "      <td>0.891347</td>\n",
       "      <td>0.901177</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "341       1.811287         0.110419         0.892488          0.902574   \n",
       "340       2.257520         0.159539         0.892409          0.902353   \n",
       "338       1.360242         0.158142         0.892244          0.902092   \n",
       "347       1.722359         0.115429         0.892205          0.902219   \n",
       "339       1.300365         0.151131         0.892064          0.902070   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "341            gini               7                 15                      1   \n",
       "340            gini               7                 15                      1   \n",
       "338            gini               7                 15                      1   \n",
       "347            gini               7                 15                      2   \n",
       "339            gini               7                 15                      1   \n",
       "\n",
       "    param_n_estimators                                             params  \\\n",
       "341                120  {u'max_features': 15, u'n_estimators': 120, u'...   \n",
       "340                110  {u'max_features': 15, u'n_estimators': 110, u'...   \n",
       "338                 90  {u'max_features': 15, u'n_estimators': 90, u'c...   \n",
       "347                120  {u'max_features': 15, u'n_estimators': 120, u'...   \n",
       "339                100  {u'max_features': 15, u'n_estimators': 100, u'...   \n",
       "\n",
       "     ...  split2_test_score  split2_train_score  split3_test_score  \\\n",
       "341  ...           0.889195            0.905240           0.891336   \n",
       "340  ...           0.889159            0.905136           0.891037   \n",
       "338  ...           0.888494            0.904592           0.890898   \n",
       "347  ...           0.890335            0.905915           0.891106   \n",
       "339  ...           0.888496            0.904749           0.890673   \n",
       "\n",
       "     split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "341            0.901799           0.891492            0.901468      0.234767   \n",
       "340            0.901514           0.891418            0.901296      0.633057   \n",
       "338            0.901091           0.891957            0.901484      0.066677   \n",
       "347            0.901407           0.891459            0.901505      0.107170   \n",
       "339            0.901019           0.891347            0.901177      0.017586   \n",
       "\n",
       "     std_score_time  std_test_score  std_train_score  \n",
       "341        0.002839        0.002382         0.001410  \n",
       "340        0.042878        0.002425         0.001430  \n",
       "338        0.002878        0.002472         0.001298  \n",
       "347        0.005763        0.001753         0.001951  \n",
       "339        0.014723        0.002504         0.001384  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывести 5 лучших результатов\n",
    "pd.DataFrame(grid_rfc.cv_results_).sort_values(by = ['mean_test_score'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.12, loss='exponential', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=125,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим модель с оптимальными параметрами которые удалось подобрать\n",
    "clf = GradientBoostingClassifier(n_estimators = 125, learning_rate=0.12, max_depth=6, loss = 'exponential')\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем метрики на тренировочном наборе\n",
    "actual_labels = clf.predict(train_data)\n",
    "# actual_labels_proba = clf.predict_proba(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC = 0.9219837898688904\n",
      "accuracy = 0.9222175506036399\n",
      "precision = 0.932384118421878\n",
      "recall = 0.9076753984246199\n",
      "f1 = 0.9198638613861386\n"
     ]
    }
   ],
   "source": [
    "print \"AUC_ROC =\", metrics.roc_auc_score(train_labels, actual_labels)\n",
    "print \"accuracy =\", clf.score(train_data, train_labels)\n",
    "print \"precision =\", metrics.precision_score(train_labels, actual_labels)\n",
    "print \"recall =\", metrics.recall_score(train_labels, actual_labels)\n",
    "print \"f1 =\", metrics.f1_score(train_labels, actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC_ROC = 0.5021491001564492\n",
    "# accuracy = 0.9250191277735271\n",
    "# precision = 0.8571428571428571\n",
    "# recall = 0.004357298474945534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.54284531e-05, 1.21862668e-02, 5.07090427e-04, 2.20298645e-02,\n",
       "       1.20098555e-03, 5.88355047e-03, 1.92129214e-03, 3.45027991e-03,\n",
       "       0.00000000e+00, 2.15564017e-02, 9.95565737e-04, 1.27381165e-03,\n",
       "       1.05834310e-02, 1.18279009e-03, 4.03879505e-03, 1.60025400e-03,\n",
       "       2.47491740e-02, 4.06139517e-04, 3.26227311e-03, 5.73597924e-04,\n",
       "       4.29518114e-03, 1.45100370e-01, 2.04494731e-02, 7.03916762e-03,\n",
       "       1.67933163e-03, 2.26691970e-02, 6.18175506e-03, 2.36787060e-03,\n",
       "       1.62720015e-03, 1.01380409e-02, 4.09130512e-04, 4.08880464e-03,\n",
       "       2.65768091e-03, 4.65833081e-03, 2.97450141e-02, 6.27821101e-05,\n",
       "       9.93185935e-03, 5.49567259e-03, 3.80804477e-04, 1.32507280e-02,\n",
       "       2.02990061e-01, 1.75778724e-03, 1.32369889e-02, 7.44742448e-03,\n",
       "       6.07777986e-04, 8.85020208e-03, 4.22874211e-04, 3.23222214e-03,\n",
       "       9.65514393e-03, 1.52618183e-02, 7.76517098e-03, 8.17391701e-03,\n",
       "       6.07350642e-05, 1.55055269e-03, 3.96114116e-04, 5.59073274e-04,\n",
       "       2.09943843e-03, 3.79026108e-02, 3.57452834e-03, 4.46313124e-04,\n",
       "       1.03185353e-03, 1.22107562e-03, 8.87493579e-04, 6.83216936e-04,\n",
       "       6.96619550e-04, 1.14586260e-02, 2.48108901e-04, 7.46619019e-03,\n",
       "       3.31080142e-03, 1.12432418e-03, 5.86691505e-04, 9.71510932e-03,\n",
       "       1.26234103e-03, 3.57650097e-03, 5.45231437e-02, 4.02432072e-03,\n",
       "       1.44891595e-03, 1.50513177e-02, 4.60244546e-04, 5.75958423e-03,\n",
       "       5.77952943e-04, 5.07710910e-04, 2.40292794e-03, 1.99733148e-04,\n",
       "       8.93508018e-04, 5.80705521e-04, 1.19573539e-04, 3.09019603e-04,\n",
       "       3.14887732e-03, 2.56863260e-04, 8.61369759e-04, 1.96644960e-03,\n",
       "       7.70462808e-04, 8.41833446e-02, 3.36353999e-04, 3.83362823e-03,\n",
       "       9.00591361e-04, 3.85246303e-04, 3.71529618e-02, 4.10099188e-04])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важность признаков\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестовый набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var5',\n",
       " 'Var6',\n",
       " 'Var7',\n",
       " 'Var13',\n",
       " 'Var16',\n",
       " 'Var21',\n",
       " 'Var24',\n",
       " 'Var25',\n",
       " 'Var27',\n",
       " 'Var28',\n",
       " 'Var30',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var44',\n",
       " 'Var51',\n",
       " 'Var53',\n",
       " 'Var57',\n",
       " 'Var64',\n",
       " 'Var65',\n",
       " 'Var69',\n",
       " 'Var72',\n",
       " 'Var73',\n",
       " 'Var74',\n",
       " 'Var76',\n",
       " 'Var78',\n",
       " 'Var81',\n",
       " 'Var83',\n",
       " 'Var85',\n",
       " 'Var88',\n",
       " 'Var94',\n",
       " 'Var106',\n",
       " 'Var109',\n",
       " 'Var111',\n",
       " 'Var112',\n",
       " 'Var113',\n",
       " 'Var117',\n",
       " 'Var119',\n",
       " 'Var123',\n",
       " 'Var124',\n",
       " 'Var125',\n",
       " 'Var126',\n",
       " 'Var132',\n",
       " 'Var133',\n",
       " 'Var134',\n",
       " 'Var138',\n",
       " 'Var140',\n",
       " 'Var143',\n",
       " 'Var144',\n",
       " 'Var149',\n",
       " 'Var153',\n",
       " 'Var160',\n",
       " 'Var163',\n",
       " 'Var173',\n",
       " 'Var177',\n",
       " 'Var180',\n",
       " 'Var181',\n",
       " 'Var188',\n",
       " 'Var189',\n",
       " 'Var191=NA',\n",
       " 'Var194=NA',\n",
       " 'Var196=z3mO',\n",
       " 'Var203=9_Y1',\n",
       " 'Var203=HLqf',\n",
       " 'Var203=NA',\n",
       " 'Var205=VpdQ',\n",
       " 'Var205=sJzTlal',\n",
       " 'Var207=5iay',\n",
       " 'Var207=7M47J5GA0pTYIFxg5uy',\n",
       " 'Var207=DHn_WUyBhW_whjA88g9bvA64_',\n",
       " 'Var207=me75fM6ugJ',\n",
       " 'Var210=3av_',\n",
       " 'Var210=g5HH',\n",
       " 'Var210=oT7d',\n",
       " 'Var210=uKAI',\n",
       " 'Var211=L84s',\n",
       " 'Var213=KdSa',\n",
       " 'Var215=NA',\n",
       " 'Var218=NA',\n",
       " 'Var218=UYBR',\n",
       " 'Var218=cJvF',\n",
       " 'Var219=AU8_WTd',\n",
       " 'Var219=FzaX',\n",
       " 'Var219=NA',\n",
       " 'Var221=Al6ZaUT',\n",
       " 'Var221=QKW8DRm',\n",
       " 'Var221=oslk',\n",
       " 'Var221=z4pH',\n",
       " 'Var221=zCkv',\n",
       " 'Var223=LM8l689qOp',\n",
       " 'Var223=M_8D',\n",
       " 'Var223=jySVZNlOJy',\n",
       " 'Var224=4n2X',\n",
       " 'Var225=ELof',\n",
       " 'Var225=NA',\n",
       " 'Var225=kG3k',\n",
       " 'Var227=ZI9m',\n",
       " 'Var227=nIGXDli',\n",
       " 'Var227=vJ_w8kB',\n",
       " 'Var229=NA',\n",
       " 'Var229=am7c']"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 230)\n"
     ]
    }
   ],
   "source": [
    "# получаем нужные признаки из обучения\n",
    "name_col_numb = columns_top100[:58]\n",
    "name_col_categ = columns_top100[58:]\n",
    "\n",
    "# Предобрабатываем тестовый набор\n",
    "print test_data.shape\n",
    "\n",
    "# отделяем числовые и категориальные признаки и удаляем полностью пустые признаки\n",
    "# data_numb_test = test_data.iloc[:,0:190].dropna(axis=1, how='all')\n",
    "# data_numb_test = test_data[name_col_numb]\n",
    "data_numb_test = test_data[data_numb.columns]\n",
    "data_categ_test = test_data.iloc[:,190:]\n",
    "\n",
    "# data_dummies = pd.get_dummies(data_categ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 174)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВЕЩЕСТВЕННЫЕ признаки\n",
    "numeric_means_test = data_numb_test.mean(axis=0, skipna=True)\n",
    "# Заполним пропущенные численные значения средними\n",
    "data_numb_test = data_numb_test.fillna(numeric_means_test, axis=0)\n",
    "\n",
    "data_numb_test =pd.DataFrame(scaler.transform(data_numb_test.values), index=data_numb_test.index, columns=data_numb_test.columns)\n",
    "\n",
    "# data_numb_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем только важные признаки\n",
    "data_numb_test = data_numb_test[name_col_numb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# КАТЕГОРИАЛЬНЫЕ ПРИЗНАКИ\n",
    "# берем только колонки используемые в обучении\n",
    "# data_categ_test = data_categ_test[data_categ.columns]\n",
    "data_categ_test = data_categ_test.fillna('NA').applymap(lambda s: str(s))\n",
    "\n",
    "\n",
    "# удалим те колонки где больше 20 категорий и меньше 2 (эти колонки не информативны)\n",
    "# name_del = [name for name, var in data_categ_test.iteritems() if var.value_counts(dropna=True).shape[0] > 20 or var.value_counts(dropna=True).shape[0] < 2]\n",
    "# data_categ_test = data_categ_test.drop(labels=name_del, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 58)\n",
      "(10000, 40)\n"
     ]
    }
   ],
   "source": [
    "print data_numb_test.shape\n",
    "print data_categ_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кодируем категориальные признаки\n",
    "# data_dummies_test = pd.get_dummies(data_categ_test)\n",
    "\n",
    "data_dummies_test = encoder.transform(data_categ_test.T.to_dict().values())\n",
    "# data_dummies_test = np.where(data_dummies_test == np.nan, data_dummies_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ind = [ind for ind, el in enumerate(encoder.feature_names_) if el in name_col_categ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берём только колонки которые вошли в топ 100\n",
    "data_dummies_test = data_dummies_test[:, list_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 58)\n",
      "(10000, 42)\n"
     ]
    }
   ],
   "source": [
    "print data_numb_test.shape\n",
    "print data_dummies_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем числовые признаки и закодированные категориальные\n",
    "test_data = np.hstack((data_numb_test.values, data_dummies_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = clf.predict(test_data)\n",
    "test_labels_proba = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраняем результат для Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_labels_proba[:,1], columns=['result'])  \n",
    "df.index.name = 'ID'\n",
    "# df['index'] = df.index\n",
    "# df.astype({\"ID\": int, \"result\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('output.csv', df, delimiter=',', fmt='%f', header='ID, result')\n",
    "df.to_csv('output_gb.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес (не использовался, пропускать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# max_depth - максимальная глубина\n",
    "# learning_rate - насколько сильно каждое дерево будет пытаться исправить ошибки предыдущих деревьев.\n",
    "# min_samples_leaf - Ограничение на число объектов в листьях\n",
    "parameters_grid = {\n",
    "    'n_estimators' : range(70, 130, 10),\n",
    "    'max_depth': range(2, 8, 1),\n",
    "    'max_features': ['sqrt', 'log2', 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "# n_jobs=-1: строить на максимально возможном числе процессоров\n",
    "# Будем использовать метод стратификации который делит соотношение классов в обучающей выборке на равное количество\n",
    "skf = model_selection.StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "classifier = RandomForestClassifier(random_state=0, class_weight = 'balanced', n_jobs=-1)\n",
    "grid_rfc = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'roc_auc', cv = skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53min 6s, sys: 2min 21s, total: 55min 27s\n",
      "Wall time: 1h 41min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [70, 80, 90, 100, 110, 120], 'max_features': ['sqrt', 'log2', 10, 15, 20], 'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4, 5, 6, 7], 'min_samples_leaf': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=7, max_features=15,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=120, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8924879337816848\n",
      "{'max_features': 15, 'n_estimators': 120, 'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "print grid_rfc.best_score_\n",
    "print grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.811287</td>\n",
       "      <td>0.110419</td>\n",
       "      <td>0.892488</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 120, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889195</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.901799</td>\n",
       "      <td>0.891492</td>\n",
       "      <td>0.901468</td>\n",
       "      <td>0.234767</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.257520</td>\n",
       "      <td>0.159539</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.902353</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 110, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889159</td>\n",
       "      <td>0.905136</td>\n",
       "      <td>0.891037</td>\n",
       "      <td>0.901514</td>\n",
       "      <td>0.891418</td>\n",
       "      <td>0.901296</td>\n",
       "      <td>0.633057</td>\n",
       "      <td>0.042878</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1.360242</td>\n",
       "      <td>0.158142</td>\n",
       "      <td>0.892244</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 90, u'c...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888494</td>\n",
       "      <td>0.904592</td>\n",
       "      <td>0.890898</td>\n",
       "      <td>0.901091</td>\n",
       "      <td>0.891957</td>\n",
       "      <td>0.901484</td>\n",
       "      <td>0.066677</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.722359</td>\n",
       "      <td>0.115429</td>\n",
       "      <td>0.892205</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 120, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890335</td>\n",
       "      <td>0.905915</td>\n",
       "      <td>0.891106</td>\n",
       "      <td>0.901407</td>\n",
       "      <td>0.891459</td>\n",
       "      <td>0.901505</td>\n",
       "      <td>0.107170</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1.300365</td>\n",
       "      <td>0.151131</td>\n",
       "      <td>0.892064</td>\n",
       "      <td>0.902070</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'max_features': 15, u'n_estimators': 100, u'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888496</td>\n",
       "      <td>0.904749</td>\n",
       "      <td>0.890673</td>\n",
       "      <td>0.901019</td>\n",
       "      <td>0.891347</td>\n",
       "      <td>0.901177</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "341       1.811287         0.110419         0.892488          0.902574   \n",
       "340       2.257520         0.159539         0.892409          0.902353   \n",
       "338       1.360242         0.158142         0.892244          0.902092   \n",
       "347       1.722359         0.115429         0.892205          0.902219   \n",
       "339       1.300365         0.151131         0.892064          0.902070   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "341            gini               7                 15                      1   \n",
       "340            gini               7                 15                      1   \n",
       "338            gini               7                 15                      1   \n",
       "347            gini               7                 15                      2   \n",
       "339            gini               7                 15                      1   \n",
       "\n",
       "    param_n_estimators                                             params  \\\n",
       "341                120  {u'max_features': 15, u'n_estimators': 120, u'...   \n",
       "340                110  {u'max_features': 15, u'n_estimators': 110, u'...   \n",
       "338                 90  {u'max_features': 15, u'n_estimators': 90, u'c...   \n",
       "347                120  {u'max_features': 15, u'n_estimators': 120, u'...   \n",
       "339                100  {u'max_features': 15, u'n_estimators': 100, u'...   \n",
       "\n",
       "     ...  split2_test_score  split2_train_score  split3_test_score  \\\n",
       "341  ...           0.889195            0.905240           0.891336   \n",
       "340  ...           0.889159            0.905136           0.891037   \n",
       "338  ...           0.888494            0.904592           0.890898   \n",
       "347  ...           0.890335            0.905915           0.891106   \n",
       "339  ...           0.888496            0.904749           0.890673   \n",
       "\n",
       "     split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "341            0.901799           0.891492            0.901468      0.234767   \n",
       "340            0.901514           0.891418            0.901296      0.633057   \n",
       "338            0.901091           0.891957            0.901484      0.066677   \n",
       "347            0.901407           0.891459            0.901505      0.107170   \n",
       "339            0.901019           0.891347            0.901177      0.017586   \n",
       "\n",
       "     std_score_time  std_test_score  std_train_score  \n",
       "341        0.002839        0.002382         0.001410  \n",
       "340        0.042878        0.002425         0.001430  \n",
       "338        0.002878        0.002472         0.001298  \n",
       "347        0.005763        0.001753         0.001951  \n",
       "339        0.014723        0.002504         0.001384  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывести 5 лучших результатов\n",
    "pd.DataFrame(grid_rfc.cv_results_).sort_values(by = ['mean_test_score'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukashov/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=7, max_features=15,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=90, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим модель с оптимальными параметрами которые удалось подобрать\n",
    "clf2 = RandomForestClassifier(max_features= 15, \n",
    "                              n_estimators= 90, \n",
    "                              criterion= 'gini', \n",
    "                              max_depth= 7, \n",
    "                              min_samples_leaf= 1, \n",
    "                              class_weight = 'balanced', \n",
    "                              n_jobs=-1)\n",
    "\n",
    "clf2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем метрики на тренировочном наборе\n",
    "actual_labels2 = clf2.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC = 0.8080813007103829\n",
      "accuracy = 0.8082767733797825\n",
      "precision = 0.8106696511844805\n",
      "recall = 0.7961165048543689\n",
      "f1 = 0.8033271719038817\n"
     ]
    }
   ],
   "source": [
    "print \"AUC_ROC =\", metrics.roc_auc_score(train_labels, actual_labels2)\n",
    "print \"accuracy =\", clf2.score(train_data, train_labels)\n",
    "print \"precision =\", metrics.precision_score(train_labels, actual_labels2)\n",
    "print \"recall =\", metrics.recall_score(train_labels, actual_labels2)\n",
    "print \"f1 =\", metrics.f1_score(train_labels, actual_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22415677e-02, 1.76032893e-03, 6.33748705e-04, 3.27039865e-04,\n",
       "       4.33493921e-02, 2.14904315e-03, 9.48536278e-03, 1.75662062e-04,\n",
       "       8.75451571e-04, 6.98228478e-03, 2.13701875e-01, 4.38740465e-02,\n",
       "       7.75976167e-03, 1.53237631e-02, 3.98628724e-03, 3.29728433e-03,\n",
       "       1.85406399e-03, 2.20321031e-02, 2.04275010e-02, 2.65876504e-01,\n",
       "       3.77895374e-03, 7.89218908e-03, 9.68395427e-04, 2.97005635e-02,\n",
       "       2.29238042e-03, 1.65723673e-03, 6.90042658e-05, 9.72867813e-03,\n",
       "       8.96927545e-03, 1.30630978e-03, 4.69150155e-03, 4.91811871e-03,\n",
       "       5.44928196e-05, 4.82206898e-03, 3.98901665e-02, 3.18548579e-02,\n",
       "       4.15367198e-03, 3.07792343e-04, 3.09219303e-04, 1.33696018e-02,\n",
       "       6.23673508e-03, 1.62859069e-05, 9.11715459e-04, 1.96676299e-04,\n",
       "       7.88442874e-02, 4.92098494e-03, 7.31778818e-03, 3.11854800e-04,\n",
       "       0.00000000e+00, 5.43961224e-02])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важность признаков\n",
    "clf2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ТЕСТОВЫЙ НАБОР\n",
    "test_labels2 = clf2.predict(test_data)\n",
    "test_labels_proba2 = clf2.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_labels_proba2[:,1], columns=['result'])  \n",
    "df.index.name = 'ID'\n",
    "df.to_csv('output.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    for learn_rate in list_learning_rate\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_scoring = []\n",
    "n_trees = [70, 75, 80, 85, 90]\n",
    "list_max_depth = [4, 5, 6]\n",
    "# list_n_child = [1, 2, 3]\n",
    "list_learning_rate = [0.09, 0.1, 0.11]\n",
    "for n_tree in n_trees:\n",
    "    for n_depth in list_max_depth:\n",
    "        for learn_rate in list_learning_rate:\n",
    "            estimator = xgb.XGBClassifier(learning_rate=learn_rate, max_depth=n_depth, n_estimators=n_tree, min_child_weight=2, n_jobs=2, seed=0)\n",
    "            score = model_selection.cross_val_score(estimator, train_data, train_labels, \n",
    "                                                     scoring = 'roc_auc', cv = 5)    \n",
    "            xgb_scoring.append(score)\n",
    "\n",
    "            print n_tree, n_depth, learn_rate, np.array(score).mean()\n",
    "    \n",
    "xgb_scoring = np.asmatrix(xgb_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308558058712322"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: если использовать параметры больше, то всё переобучается\n",
    "xgb_scoring.mean(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=2, missing=None, n_estimators=75,\n",
       "       n_jobs=2, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = xgb.XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=75, min_child_weight=2, n_jobs=2, seed=0)\n",
    "clf3.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем метрики на тренировочном наборе\n",
    "actual_labels3 = clf3.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC = 0.866813160245906\n",
      "precision = 0.8786189420335762\n",
      "recall = 0.8468583989741711\n",
      "f1 = 0.8624463652757913\n"
     ]
    }
   ],
   "source": [
    "print \"AUC_ROC =\", metrics.roc_auc_score(train_labels, actual_labels3)\n",
    "# print \"accuracy =\", clf3.score(train_data, train_labels)\n",
    "print \"precision =\", metrics.precision_score(train_labels, actual_labels3)\n",
    "print \"recall =\", metrics.recall_score(train_labels, actual_labels3)\n",
    "print \"f1 =\", metrics.f1_score(train_labels, actual_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = clf.predict(test_data)\n",
    "test_labels_proba3 = clf3.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_labels_proba3[:,1], columns=['result'])  \n",
    "df.index.name = 'ID'\n",
    "df.to_csv('output.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
